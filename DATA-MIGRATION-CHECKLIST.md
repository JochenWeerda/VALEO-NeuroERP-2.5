# üìã Datenmigrationen-Checkliste ‚Äì L3 ‚Üí VALERO NeuroERP

**Zweck:** Sichere, vollst√§ndige und nachvollziehbare Migration von L3 (doku.service-erp.de) nach NeuroERP.

**Scope:** Stammdaten, Bewegungsdaten, Dokumente, Historie

---

## üéØ Migrations-Strategie

### Gesamtansatz: Stepwise Migration + Dual-Run

```
Phase 1: Stammdaten (Kunden, Artikel, Lieferanten)
   ‚Üì
Phase 2: Historische Daten (Vertr√§ge, Rechnungen, Lieferscheine)
   ‚Üì
Phase 3: Laufende Gesch√§ftsvorf√§lle (parallel L3 + NeuroERP)
   ‚Üì
Phase 4: Vollumschaltung (L3 read-only)
   ‚Üì
Phase 5: L3-Archivierung (Zugriff nur noch f√ºr Audit)
```

**Dauer:** 4-8 Wochen (abh√§ngig von Datenmenge)

---

## üì¶ Daten-Kategorien

### 1. Stammdaten (Master Data)

| Entit√§t | L3-Quelle | NeuroERP-Ziel | Priorit√§t |
|---------|-----------|---------------|-----------|
| **Kunden** | `customers` | crm-domain | üî¥ HOCH |
| **Lieferanten** | `suppliers` | procurement-domain | üî¥ HOCH |
| **Artikel** | `products` | inventory-domain | üî¥ HOCH |
| **Lager/Silos** | `warehouses` | inventory-domain | üî¥ HOCH |
| **Mitarbeiter** | `employees` | hr-domain | üü° MITTEL |
| **Fahrzeuge** | `vehicles` | fleet-domain | üü° MITTEL |

### 2. Transaktionsdaten

| Entit√§t | L3-Quelle | NeuroERP-Ziel | Priorit√§t |
|---------|-----------|---------------|-----------|
| **Vertr√§ge** | `contracts` | contracts-domain | üî¥ HOCH |
| **Rechnungen** | `invoices` | sales-domain | üî¥ HOCH |
| **Lieferscheine** | `delivery_notes` | weighing-domain | üî¥ HOCH |
| **Wiegungen** | `weighings` | weighing-domain | üî¥ HOCH |
| **Zahlungen** | `payments` | finance-domain | üü° MITTEL |
| **Pr√ºfergebnisse** | `quality_checks` | quality-domain | üü¢ NIEDRIG |

### 3. Dokumente & Anh√§nge

| Typ | L3-Quelle | NeuroERP-Ziel | Speicher |
|-----|-----------|---------------|----------|
| **Rechnungs-PDFs** | `/docs/invoices/` | document-domain | S3 |
| **Vertrags-PDFs** | `/docs/contracts/` | document-domain | S3 |
| **Zertifikate** | `/docs/certs/` | regulatory-domain | S3 |
| **Pr√ºfprotokolle** | `/docs/quality/` | quality-domain | S3 |

---

## üó∫Ô∏è Feldmapping (Beispiel: Kunden)

### L3 ‚Üí NeuroERP (CRM-Domain)

| L3-Feld | NeuroERP-Feld | Transformation | Validierung |
|---------|---------------|----------------|-------------|
| `customer_id` | `customerId` | Direct | UUID-Format |
| `name` | `companyName` | Direct | Min 1 char |
| `vat_id` | `vatId` | Trim + Uppercase | DE\d{9} |
| `address` | `address.street` | Split | - |
| `zip` | `address.postalCode` | Direct | 5 digits |
| `city` | `address.city` | Direct | - |
| `country_code` | `address.country` | ISO 3166-1 | DE, AT, CH |
| `payment_terms` | `paymentTerms` | Days ‚Üí Enum | 14d, 30d, 60d |
| `credit_limit` | `creditLimit` | EUR cents | > 0 |

**Spezialf√§lle:**
- `customer_group` (L3) ‚Üí `segmentation.tier` (NeuroERP) via Mapping-Tabelle
- `salesperson` (L3) ‚Üí `owner.userId` (NeuroERP) via Employee-Lookup

---

## üß™ Test-Strategie

### 1. Mapping-Tests (Dry-Run)

**Schritt 1:** Export aus L3 (10 Testkunden)
```bash
curl https://doku.service-erp.de/api/customers?limit=10 > test_customers.json
```

**Schritt 2:** Mapping ausf√ºhren (ohne Import)
```bash
npm run migrate:test -- --source test_customers.json --mapping customers.map.json
```

**Schritt 3:** Validierung
- ‚úÖ Alle Pflichtfelder gemappt
- ‚úÖ Keine Dubletten (customerId unique)
- ‚úÖ Referenzen aufl√∂sbar (salesperson ‚Üí userId)

**Ergebnis:** Mapping-Report mit Fehler-/Warnungsanzahl

---

### 2. Probeimport (Staging)

**Schritt 1:** 100 Kunden importieren (Staging-DB)
```bash
npm run migrate:import -- --env staging --source customers_sample.json --limit 100
```

**Schritt 2:** Plausibilit√§tspr√ºfungen
- Anzahl: 100 Datens√§tze in DB?
- Referenzen: Alle `ownerId` vorhanden?
- Duplikate: Keine doppelten `customerId`?

**Schritt 3:** Stichproben (manuell)
- 10 zuf√§llige Kunden √∂ffnen
- Felder gegen L3 vergleichen

**Ergebnis:** ‚úÖ/‚ùå Freigabe f√ºr Vollimport

---

### 3. Vollimport (Production)

**Schritt 1:** Backup erstellen
```bash
pg_dump -h prod-db -U valero -d neuroerp > backup_pre_migration.sql
```

**Schritt 2:** Import starten (batched)
```bash
npm run migrate:import -- --env production --source customers_full.json --batch-size 1000
```

**Monitoring:**
- Fortschritt: 1000/5000 (20%)
- Fehler: 12 (DLQ)
- Dauer: ~15 Min

**Schritt 3:** Post-Import-Validierung
```bash
# Z√§hlung
SELECT COUNT(*) FROM customers WHERE tenant_id = 'tenant-abc';

# Integrit√§tspr√ºfung
GET /audit/api/v1/integrity/check?from=<migration-start>
```

---

## üîÑ Rollback-Strategie

### Option 1: DB-Restore (f√ºr Vollimport-Fehler)

```bash
# Stop Services
kubectl scale deployment document-domain --replicas=0

# Restore Backup
psql -h prod-db -U valero -d neuroerp < backup_pre_migration.sql

# Start Services
kubectl scale deployment document-domain --replicas=3
```

**Downtime:** ~10-30 Min (abh√§ngig von DB-Gr√∂√üe)

---

### Option 2: Soft-Delete (f√ºr Partial-Import-Fehler)

```sql
-- Markiere migrierte Datens√§tze als ung√ºltig
UPDATE customers SET deleted_at = NOW()
WHERE created_at > '<migration-start>' AND migration_source = 'L3';
```

**Downtime:** ‚ùå Keine

---

### Option 3: DLQ-Nachbearbeitung (f√ºr einzelne Fehler)

```bash
# Export Failed Records
GET /integration/api/v1/dlq?source=L3&entity=customers

# Korrigieren, Re-Import
npm run migrate:retry -- --dlq-id <job-id>
```

**Downtime:** ‚ùå Keine

---

## üìä Feldmapping-Tabellen (Referenz)

### Artikelgruppen (L3 ‚Üí NeuroERP)

| L3-Code | L3-Name | NeuroERP-Code | NeuroERP-Name |
|---------|---------|---------------|---------------|
| `WZ` | Weizen | `WHEAT` | Weichweizen |
| `GS` | Gerste | `BARLEY` | Futtergerste |
| `RP` | Raps | `RAPESEED` | Raps (konventionell) |
| `DM` | D√ºnger | `FERTILIZER` | Minerald√ºnger |

### Zahlungsbedingungen

| L3-Code | NeuroERP-Enum | Tage |
|---------|---------------|------|
| `14T` | `NET_14` | 14 |
| `30T` | `NET_30` | 30 |
| `SKT2` | `DISCOUNT_2_14_NET_30` | 2% bei 14d, sonst 30d |

---

## ‚úÖ Migrations-Checkliste

### Vor der Migration

- [ ] **Scope definiert** (welche Daten, welcher Zeitraum)
- [ ] **Mapping-Tabellen erstellt** (alle Felder dokumentiert)
- [ ] **Test-Exports aus L3** (10-100 Datens√§tze)
- [ ] **Dry-Run erfolgreich** (Mapping ohne Import)
- [ ] **Backup erstellt** (Production-DB)
- [ ] **Rollback-Plan bereit** (DB-Restore oder Soft-Delete)
- [ ] **Stakeholder informiert** (Timeline, Downtime)
- [ ] **Audit: Migration als Draft protokolliert**

### W√§hrend der Migration

- [ ] **Batch-Import l√§uft** (Progress-Monitoring)
- [ ] **DLQ √ºberwacht** (Fehlerrate < 1%)
- [ ] **Logs √ºberwacht** (keine Crashes)
- [ ] **Referenzen aufl√∂sbar** (Foreign Keys valide)
- [ ] **Notifications verschickt** (Start, Fortschritt)
- [ ] **Audit: Jede Batch geloggt**

### Nach der Migration

- [ ] **Z√§hlung korrekt** (SELECT COUNT vs. L3-Export)
- [ ] **Stichproben** (10-20 Datens√§tze manuell pr√ºfen)
- [ ] **Referenzen valide** (keine Orphans)
- [ ] **Integrit√§tspr√ºfung** (Audit-Domain)
- [ ] **DLQ abgearbeitet** (Fehler korrigiert und re-imported)
- [ ] **Dokumente migriert** (PDFs in S3, Metadaten in DB)
- [ ] **UAT-Tests** (User Acceptance Testing)
- [ ] **Freigabe durch Stakeholder**
- [ ] **Audit: Migration als Completed protokolliert**
- [ ] **L3: Read-Only oder Archiv-Modus**

---

## üîç Qualit√§tssicherung

### Automatische Validierung

```typescript
// Beispiel: Validierung nach Import
async function validateCustomerMigration(tenantId: string) {
  const stats = await db.execute(`
    SELECT 
      COUNT(*) as total,
      COUNT(DISTINCT customer_id) as unique_ids,
      COUNT(CASE WHEN vat_id IS NULL THEN 1 END) as missing_vat,
      COUNT(CASE WHEN credit_limit < 0 THEN 1 END) as negative_credit
    FROM customers
    WHERE tenant_id = $1 AND migration_source = 'L3'
  `, [tenantId]);

  return {
    total: stats.total,
    duplicates: stats.total - stats.unique_ids,
    missingVat: stats.missing_vat,
    negativeCredit: stats.negative_credit,
    valid: stats.duplicates === 0 && stats.negative_credit === 0
  };
}
```

### Manuelle Stichproben

**Kriterien:**
- ‚úÖ 10 zuf√§llige Datens√§tze gegen L3 vergleichen
- ‚úÖ Alle Pflichtfelder gef√ºllt
- ‚úÖ Formatierung korrekt (Datum, W√§hrung, PLZ)
- ‚úÖ Referenzen aufl√∂sbar (Artikel ‚Üí customerId)

---

## üö® Risiken & Mitigationen

| Risiko | Wahrscheinlichkeit | Impact | Mitigation |
|--------|-------------------|--------|------------|
| **Dubletten** | Mittel | Hoch | Unique-Constraints, Pre-Check |
| **Referenz-Fehler** | Hoch | Hoch | Foreign-Key-Validierung vor Import |
| **Daten-Verlust** | Niedrig | Kritisch | Backup vor Migration, Vergleich Counts |
| **Fehlerhafte Mappings** | Mittel | Mittel | Dry-Run, Stichproben, DLQ |
| **Performance** | Niedrig | Mittel | Batching (1000er), Off-Peak-Import |

---

## üìÅ Migrations-Artefakte

### Input
- `customers_l3_export.json` (L3-Export)
- `customers_mapping.json` (Feldmapping)
- `customers_transformations.js` (Custom-Logic)

### Output
- `migration_report_customers.pdf` (Status, Fehler, Statistiken)
- `dlq_customers.json` (fehlgeschlagene Datens√§tze)
- `audit_trail_migration.json` (revisionssicher)

### Speicherort
```
/migrations/
  ‚îú‚îÄ‚îÄ l3-to-neuroerp/
  ‚îÇ   ‚îú‚îÄ‚îÄ exports/
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ customers_2025-10-01.json
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ contracts_2025-10-01.json
  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ invoices_2025-10-01.json
  ‚îÇ   ‚îú‚îÄ‚îÄ mappings/
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ customers.map.json
  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ contracts.map.json
  ‚îÇ   ‚îú‚îÄ‚îÄ reports/
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ migration_report_customers.pdf
  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dlq_customers.json
  ‚îÇ   ‚îî‚îÄ‚îÄ backups/
  ‚îÇ       ‚îî‚îÄ‚îÄ backup_pre_migration_2025-10-01.sql
```

---

## üîÑ Dual-Run-Strategie

### Phase 1-2: NeuroERP als Slave (read-only)
```
L3 (Master) ‚îÄ‚îÄ‚îê
              ‚îú‚îÄ‚îÄ> NeuroERP (Sync, Reports)
Neue Daten  ‚îÄ‚îÄ‚îò
```

### Phase 3: Dual-Write (beide Systeme parallel)
```
Neue Daten ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ> L3 (Master)
             ‚îî‚îÄ‚îÄ> NeuroERP (Testing)
```

### Phase 4: NeuroERP als Master
```
Neue Daten ‚îÄ‚îÄ> NeuroERP (Master)
                  ‚îú‚îÄ‚îÄ> L3 (read-only, Archiv)
                  ‚îî‚îÄ‚îÄ> Reports, Analytics
```

**Dauer Phase 3:** 2-4 Wochen (Validierung, User-Training)

---

## üß™ Test-Szenarien

### Szenario 1: Kundenstamm (100 Kunden)

**Input:** `customers_test.json` (100 Datens√§tze)

**Schritte:**
1. Dry-Run (Mapping-Validierung)
2. Staging-Import
3. Stichproben (10 Kunden manuell pr√ºfen)
4. Freigabe f√ºr Production-Import

**Success-Kriterien:**
- ‚úÖ 100 Datens√§tze importiert
- ‚úÖ 0 Fehler in DLQ
- ‚úÖ Alle VAT-IDs korrekt formatiert
- ‚úÖ Payment-Terms gemappt

---

### Szenario 2: Vertragsdaten (500 Vertr√§ge)

**Input:** `contracts_test.json` (500 Datens√§tze, 2 Jahre Historie)

**Schritte:**
1. Referenz-Check (customerId, commodityId existieren?)
2. Datumsformat-Pr√ºfung (ISO 8601)
3. Mengen/Preise-Plausibilit√§t (> 0, < 1 Mio)
4. Import in contracts-domain

**Success-Kriterien:**
- ‚úÖ 500 Vertr√§ge importiert
- ‚úÖ Referenzen valide (0 Orphans)
- ‚úÖ Summen korrekt (Total = Œ£ Lines)
- ‚úÖ Status-Mapping korrekt (Open/Closed/Fulfilled)

---

### Szenario 3: Wiegungen (10.000 Datens√§tze)

**Input:** `weighings_2024.json` (komplettes Jahr 2024)

**Schritte:**
1. Batching (1000er-Schritte)
2. Progress-Monitoring
3. Performance-Check (< 2 Min/Batch)
4. Integrit√§tspr√ºfung (Brutto - Tara = Netto)

**Success-Kriterien:**
- ‚úÖ 10.000 Wiegungen importiert
- ‚úÖ Brutto/Tara/Netto-Berechnungen korrekt
- ‚úÖ Alle Tickets haben Document-Link (PDF)
- ‚úÖ Import-Dauer < 20 Min

---

## üìä KI-gest√ºtzte Mapping-Engine

### Automatische Vorschl√§ge

```javascript
// Beispiel: Fuzzy-Matching f√ºr Artikel-Kategorien
const l3Categories = ['WZ', 'GS', 'RP', 'DM', 'SF'];
const neuroCategories = ['WHEAT', 'BARLEY', 'RAPESEED', 'FERTILIZER', 'ANIMAL_FEED'];

// KI-Modell schl√§gt Mapping vor:
{
  "WZ": { "suggestion": "WHEAT", "confidence": 0.95 },
  "GS": { "suggestion": "BARLEY", "confidence": 0.92 },
  "RP": { "suggestion": "RAPESEED", "confidence": 0.98 },
  "DM": { "suggestion": "FERTILIZER", "confidence": 0.88 },
  "SF": { "suggestion": "ANIMAL_FEED", "confidence": 0.75 }  // niedrig ‚Üí manuell pr√ºfen
}
```

**Integration:** analytics-domain trainiert Mapping-Modell aus Mustern

---

## üîê Audit-Trail f√ºr Migration

### Was wird protokolliert?

1. **Import-Files** (Original-JSON aus L3)
   - Speicherort: S3 Bucket `valero-migrations/`
   - Retention: 10 Jahre (GoBD)

2. **Mapping-Logs**
   - Welches Feld ‚Üí wohin
   - Transformationen
   - Fehler/Warnings

3. **DLQ (Dead Letter Queue)**
   - Fehlgeschlagene Datens√§tze
   - Fehlergrund
   - Retry-Versuche

4. **Success-Metriken**
   - Importiert: 4.988 / 5.000 (99.76%)
   - DLQ: 12 (0.24%)
   - Dauer: 18 Min

5. **Audit-Events**
   ```json
   {
     "action": "IMPORT",
     "target": { "type": "Customer", "id": "migration-batch-001" },
     "payload": {
       "source": "L3",
       "count": 1000,
       "success": 998,
       "failed": 2
     }
   }
   ```

---

## üöÄ Migrations-Workflow (End-to-End)

### Woche 1-2: Vorbereitung
- [ ] L3-API-Zugang testen
- [ ] Export-Skripte erstellen
- [ ] Mapping-Tabellen definieren
- [ ] Test-Exports durchf√ºhren (10-100 Datens√§tze)
- [ ] Dry-Run erfolgreich

### Woche 3: Staging-Migration
- [ ] Stammdaten importieren (Kunden, Artikel, Lieferanten)
- [ ] Stichproben pr√ºfen
- [ ] Referenzen validieren
- [ ] Freigabe durch Stakeholder

### Woche 4: Production-Migration (Stammdaten)
- [ ] Backup erstellen
- [ ] Off-Peak-Import (nachts)
- [ ] Post-Import-Validierung
- [ ] Audit-Trail vollst√§ndig

### Woche 5-6: Transaktionsdaten
- [ ] Vertr√§ge (historisch)
- [ ] Rechnungen (historisch)
- [ ] Lieferscheine (historisch)
- [ ] Wiegungen (historisch)

### Woche 7-8: Dual-Run-Phase
- [ ] Neue Daten parallel in L3 + NeuroERP
- [ ] User-Training
- [ ] Validierung durch Fachbereiche
- [ ] Freigabe f√ºr Vollumschaltung

### Woche 9: Vollumschaltung
- [ ] NeuroERP wird Master
- [ ] L3 auf read-only
- [ ] Benachrichtigungen an alle User
- [ ] Monitoring versch√§rft (24h)

### Woche 10+: Nachbereitung
- [ ] L3-Archivierung
- [ ] DLQ abarbeiten (Restfehler)
- [ ] Dokumentation finalisieren
- [ ] Lessons Learned
- [ ] Freigabe f√ºr L3-Abschaltung (nach 6 Monaten)

---

## üìû Support-Kontakte

| Rolle | Name | Erreichbarkeit |
|-------|------|----------------|
| **Migration Lead** | TBD | migration@valero.de |
| **L3-Support** | Service-ERP | support@service-erp.de |
| **DevOps** | TBD | devops@valero.de |
| **Audit Officer** | TBD | audit@valero.de |

---

## üìà Success-Kriterien

‚úÖ **Migration erfolgreich, wenn:**
- Alle Stammdaten importiert (> 99%)
- DLQ-Rate < 1%
- Stichproben korrekt (100% Feldvergleich)
- Referenzen valide (0 Orphans)
- Audit-Trail vollst√§ndig
- Freigabe durch Stakeholder
- UAT-Tests bestanden

---

**Version:** 1.0  
**Datum:** Oktober 2025  
**Owner:** Migration Team + DevOps
